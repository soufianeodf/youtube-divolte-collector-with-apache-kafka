divolte {
  global {
    kafka {
      // Enable Kafka flushing
      enabled = true

      // Number of threads to use for flushing events to Kafka
      threads = 2

      // The maximum queue of mapped events to buffer before
      // starting to drop new ones. Note that when this buffer is full,
      // events are dropped and a warning is logged. No errors are reported
      // to the source of the events. A single buffer is shared between all
      // threads, and its size will be rounded up to the nearest power of 2.
      buffer_size = 1048576

      // The properties under the producer key in this
      // configuration are used to create a Properties object
      // which is passed to Kafka as is. At the very least,
      // configure the broker list here. For more options
      // that can be passed to a Kafka producer, see this link:
      // http://kafka.apache.org/082/documentation.html#newproducerconfigs
      producer = {
        bootstrap.servers = "localhost:9092"
        
        acks = 1
        retries = 0
        compression.type = lz4
        max.in.flight.requests.per.connection = 1
        group.id = "KafkaExampleConsumer"
      }
    }
  }

  sources {
    browser {
      type = browser
    }
  }

  mappings {
    a_mapping = {
        schema_file = "/Users/soufianeouddaf/Downloads/temp/youtube-tutorial-divolte-with-kafka/divolte-collector-0.9.0/conf/MyEventRecord.avsc"
        mapping_script_file = "/Users/soufianeouddaf/Downloads/temp/youtube-tutorial-divolte-with-kafka/divolte-collector-0.9.0/conf/mapping.groovy"
        discard_corrupted = true
        discard_duplicates = true
        sources = [browser]
        sinks = [kafka]
    }
  }

  sinks {
    // The name of the sink. (It's referred to by the mapping.)
    kafka {
      type = kafka

      // This is the name of the topic that data will be produced on
      topic = tracking
    }
  }
}